Here we target the exact part of the HTML we want to grab. This can take a bit of trial and error. Sometimes divs are nested inside more divs, until it's hard to see where anything really is. Sometimes it's not so bad.



Loop over the array, sort the issues alphabetically and create a string which separates each issue with a comma and space.

The scraped HTML page will be returned in your terminal. 

Have a look at the div tags and see where the information you want to scrape is. 

These are the tags we will target in the next little scrape.

One of the best ways to identify where to target HTML tags (on Chrome anyway) is to right-click inspect
 and browse the 'elements' section and hover over, click and search through the different tags to see where
  the information you want is. 
  
  When you hover over the different divs in 'elements' you will see on the left on the website itself 
  what you are hovering over.

[Previous page](https://github.com/jdm79/basic-bs4/blob/main/3-web-scraping-exercise-1.md)